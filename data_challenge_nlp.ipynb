{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pickle\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('NewsArticles_Top10Keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_candidate_chunk(text):    \n",
    "    #remove substring '\\\\xa0'\n",
    "    text = ' '.join([word.replace('\\\\xa0',' ').replace(\"'\", '') for word in text.split()])\n",
    "    #remove substring between &# and ;\n",
    "    text = re.sub(r'\\&#.*?\\;', \"\", text)\n",
    "    #remove word contains '\\\\'\n",
    "    text = ' '.join([word for word in text.split() if '\\\\' not in word])\n",
    "    text = re.sub(r'\\ |\\?|\\!|\\’|\\‘|\\/|\\;|\\:|\\(|\\)|\\[|\\]', ' ', text)\n",
    "\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "\n",
    "    grammar = r\"\"\"\n",
    "          NP: {<NN.*|JJ>*<NN.*>}  # chunk noun(s), adjectives and noun(s)\n",
    "          \"\"\"\n",
    "\n",
    "    chunker = nltk.RegexpParser(grammar)\n",
    "    #Parse the sentence, converting the parse tree into a tagged sequence, return (word, tag, IOB-tag)\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent)) for tagged_sent in tagged_sents))\n",
    "    # Join phrases based on IOB syntax.\n",
    "    candidates =[]\n",
    "    for key, group in itertools.groupby(all_chunks, lambda l: l[2] != 'O'):\n",
    "        if key:\n",
    "            candidates.append(' '.join(w[0] for w in group).lower())\n",
    "    #print(candidates)\n",
    "\n",
    "    #Filter by maximum keyphrase length \n",
    "    candidates = list(filter(lambda l: len(l.split()) <= 3, candidates))\n",
    "\n",
    "    #stop word list\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #punctuation list\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    #remove stopwords and punctuation\n",
    "    candidates = [candidate for candidate in candidates if candidate not in stop_words and not all(char in punctuation for char in candidate)]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Lemmatize\n",
    "\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer().lemmatize\n",
    "    candidates =  [lemmatizer(x) for x in candidates]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_candidate_words(text):    \n",
    "    #remove substring '\\\\xa0'\n",
    "    text = ' '.join([word.replace('\\\\xa0',' ').replace(\"'\", '') for word in text.split()])\n",
    "    #remove substring between &# and ;\n",
    "    text = re.sub(r'\\&#.*?\\;', \"\", text)\n",
    "    #remove word contains '\\\\'\n",
    "    text = ' '.join([word for word in text.split() if '\\\\' not in word])\n",
    "    text = re.sub(r'\\ |\\?|\\!|\\’|\\‘|\\/|\\;|\\:|\\(|\\)|\\[|\\]', ' ', text)\n",
    "\n",
    "    \n",
    "    tags = set(['JJ','JJR','JJS','NN','NNP','NNS','NNPS']) # adjective and noun word \n",
    "\n",
    "    #Parse the sentence, convert to tagged sequence, return (word, tag)\n",
    "    tagged_sents = list(itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))))\n",
    "    #stop word list\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #punctuation list\n",
    "    punctuation = set(string.punctuation)\n",
    "                        \n",
    "    # filter on certain POS tags and lowercase all words\n",
    "    candidates = [word.lower() for word, tag in tagged_sents\n",
    "                  if tag in tags and word.lower() not in stop_words\n",
    "                  and not all(char in punctuation for char in word)]\n",
    "    #Lemmatize\n",
    "\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer().lemmatize\n",
    "    candidates =  [lemmatizer(x) for x in candidates]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_df['title_chunk'] = news_df['title'].apply(lambda x:extract_candidate_chunk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['content_chunk'] = news_df['content'].apply(lambda x:extract_candidate_chunk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['title_words'] = news_df['title'].apply(lambda x:extract_candidate_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['content_words'] = news_df['content'].apply(lambda x:extract_candidate_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create chunk vobaculary\n",
    "content_chunk_vocab = []\n",
    "title_chunk_vocab = []\n",
    "for i in range(len(news_df)):\n",
    "    title_chunk_vocab.append(news_df['title_chunk'][i])\n",
    "for j in range(len(news_df)):\n",
    "    content_chunk_vocab.append(news_df['content_chunk'][j])\n",
    "\n",
    "#pickle.dump(set(title_vocab), open( \"title_phrases.p\", \"wb\" ) )\n",
    "#pickle.dump(set(content_vocab), open( \"content_phrases.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word vobaculary\n",
    "content_word_vocab = []\n",
    "title_word_vocab = []\n",
    "for i in range(len(news_df)):\n",
    "    title_word_vocab.append(news_df['title_words'][i])\n",
    "for j in range(len(news_df)):\n",
    "    content_word_vocab.append(news_df['content_words'][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "def lda_model(vocab):\n",
    "    dictionary = gensim.corpora.Dictionary(vocab)\n",
    "    #no_below (int, optional) – Keep tokens which are contained in at least no_below documents.\n",
    "    #no_above (float, optional) – Keep tokens which are contained in no more than no_above documents (fraction of total corpus size, not an absolute number).\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "    #Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples.\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in vocab]\n",
    "    from gensim import corpora, models\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=50, workers=2)\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count based LDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.148*\"samsung\" + 0.074*\"time\" + 0.061*\"million\" + 0.052*\"gamers\" + 0.051*\"netflix\" + 0.049*\"brand\" + 0.046*\"august\" + 0.043*\"ad\" + 0.039*\"marketer\" + 0.036*\"tool\"\n",
      "Topic: 1 \n",
      "Words: 0.266*\"microsoft\" + 0.117*\"vr\" + 0.102*\"pc\" + 0.064*\"preview\" + 0.055*\"developer\" + 0.050*\"sale\" + 0.047*\"new windows\" + 0.042*\"job\" + 0.039*\"machine learning\" + 0.035*\"day\"\n",
      "Topic: 2 \n",
      "Words: 0.131*\"year\" + 0.093*\"uber\" + 0.091*\"world\" + 0.077*\"china\" + 0.063*\"u.s.\" + 0.044*\"playerunknown\" + 0.043*\"launch\" + 0.042*\"machine\" + 0.038*\"video\" + 0.037*\"war\"\n",
      "Topic: 3 \n",
      "Words: 0.131*\"week\" + 0.107*\"nintendo switch\" + 0.060*\"iphone\" + 0.059*\"fund\" + 0.057*\"platform\" + 0.046*\"support\" + 0.044*\"vb live\" + 0.041*\"customer\" + 0.039*\"alexa skills\" + 0.037*\"european tech stories\"\n",
      "Topic: 4 \n",
      "Words: 0.088*\"call\" + 0.082*\"android\" + 0.072*\"way\" + 0.065*\"business\" + 0.049*\"esports\" + 0.045*\"io\" + 0.038*\"car\" + 0.038*\"hearthstone\" + 0.037*\"hero\" + 0.035*\"india\"\n",
      "Topic: 5 \n",
      "Words: 0.317*\"ai\" + 0.265*\"google\" + 0.058*\"future\" + 0.050*\"investment\" + 0.042*\"user\" + 0.032*\"u.s\" + 0.030*\"october\" + 0.029*\"e3\" + 0.025*\"aws\" + 0.019*\"everyone\"\n",
      "Topic: 6 \n",
      "Words: 0.090*\"playstation\" + 0.084*\"startup\" + 0.075*\"month\" + 0.074*\"europe\" + 0.070*\"data\" + 0.062*\"chatbots\" + 0.061*\"others\" + 0.048*\"sony\" + 0.047*\"youtube\" + 0.041*\"june\"\n",
      "Topic: 7 \n",
      "Words: 0.229*\"facebook\" + 0.219*\"amazon\" + 0.073*\"alexa\" + 0.057*\"destiny\" + 0.055*\"silicon valley\" + 0.035*\"ps4\" + 0.034*\"playerunknown s battlegrounds\" + 0.032*\"self-driving cars\" + 0.032*\"kid\" + 0.032*\"deanbeat\"\n",
      "Topic: 8 \n",
      "Words: 0.159*\"apple\" + 0.076*\"twitter\" + 0.068*\"intel\" + 0.056*\"people\" + 0.044*\"player\" + 0.044*\"overwatch\" + 0.043*\"revenue\" + 0.038*\"trump\" + 0.038*\"blockchain\" + 0.034*\"market\"\n",
      "Topic: 9 \n",
      "Words: 0.166*\"game\" + 0.128*\"company\" + 0.102*\"bot\" + 0.067*\"switch\" + 0.056*\"ar\" + 0.048*\"virtual reality\" + 0.044*\"money\" + 0.040*\"april\" + 0.039*\"life\" + 0.036*\"snap\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(title_chunk_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.081*\"apple\" + 0.058*\"tech\" + 0.029*\"ceo\" + 0.026*\"—\" + 0.025*\"iphone\" + 0.024*\"review\" + 0.019*\"day\" + 0.017*\"ipo\" + 0.016*\"company\" + 0.015*\"new\"\n",
      "Topic: 1 \n",
      "Words: 0.072*\"startup\" + 0.046*\"data\" + 0.034*\"ai\" + 0.034*\"business\" + 0.029*\"platform\" + 0.022*\"big\" + 0.022*\"new\" + 0.022*\"venture\" + 0.021*\"customer\" + 0.020*\"software\"\n",
      "Topic: 2 \n",
      "Words: 0.233*\"game\" + 0.048*\"switch\" + 0.048*\"nintendo\" + 0.032*\"mobile\" + 0.032*\"developer\" + 0.030*\"digital\" + 0.027*\"industry\" + 0.027*\"machine\" + 0.024*\"studio\" + 0.017*\"indie\"\n",
      "Topic: 3 \n",
      "Words: 0.058*\"reality\" + 0.048*\"pc\" + 0.037*\"xbox\" + 0.033*\"virtual\" + 0.027*\"valley\" + 0.027*\"way\" + 0.026*\"silicon\" + 0.026*\"playstation\" + 0.025*\"gaming\" + 0.023*\"people\"\n",
      "Topic: 4 \n",
      "Words: 0.128*\"vr\" + 0.044*\"live\" + 0.040*\"ar\" + 0.038*\"gamesbeat\" + 0.034*\"vb\" + 0.032*\"sale\" + 0.025*\"intel\" + 0.022*\"global\" + 0.021*\"weekly\" + 0.019*\"marketing\"\n",
      "Topic: 5 \n",
      "Words: 0.046*\"u.s.\" + 0.040*\"samsung\" + 0.038*\"uber\" + 0.030*\"first\" + 0.025*\"time\" + 0.024*\"market\" + 0.022*\"blockchain\" + 0.020*\"city\" + 0.017*\"new\" + 0.017*\"trump\"\n",
      "Topic: 6 \n",
      "Words: 0.080*\"facebook\" + 0.052*\"bot\" + 0.049*\"company\" + 0.032*\"video\" + 0.026*\"call\" + 0.026*\"future\" + 0.025*\"social\" + 0.020*\"duty\" + 0.018*\"beta\" + 0.018*\"messenger\"\n",
      "Topic: 7 \n",
      "Words: 0.085*\"microsoft\" + 0.049*\"new\" + 0.027*\"investment\" + 0.026*\"window\" + 0.023*\"overwatch\" + 0.021*\"update\" + 0.020*\"content\" + 0.018*\"funding\" + 0.017*\"preview\" + 0.017*\"super\"\n",
      "Topic: 8 \n",
      "Words: 0.109*\"ai\" + 0.066*\"amazon\" + 0.044*\"war\" + 0.035*\"car\" + 0.030*\"alexa\" + 0.030*\"google\" + 0.028*\"star\" + 0.024*\"assistant\" + 0.023*\"smart\" + 0.022*\"home\"\n",
      "Topic: 9 \n",
      "Words: 0.091*\"google\" + 0.051*\"service\" + 0.046*\"app\" + 0.039*\"mobile\" + 0.034*\"ad\" + 0.031*\"android\" + 0.024*\"user\" + 0.023*\"twitter\" + 0.019*\"new\" + 0.019*\"battleground\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(title_word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.041*\"nintendo\" + 0.031*\"reuters\" + 0.024*\"internet\" + 0.024*\"uber\" + 0.022*\"switch\" + 0.021*\"car\" + 0.021*\"people\" + 0.021*\"thing\" + 0.018*\"friday\" + 0.018*\"tuesday\"\n",
      "Topic: 1 \n",
      "Words: 0.075*\"world\" + 0.035*\"android\" + 0.034*\"io\" + 0.030*\"event\" + 0.027*\"game\" + 0.021*\"los angeles\" + 0.020*\"something\" + 0.020*\"year\" + 0.019*\"gamers\" + 0.015*\"place\"\n",
      "Topic: 2 \n",
      "Words: 0.040*\"year\" + 0.038*\"amazon\" + 0.033*\"deal\" + 0.029*\"company\" + 0.025*\"ceo\" + 0.022*\"sale\" + 0.019*\"term\" + 0.018*\"week\" + 0.017*\"end\" + 0.017*\"sponsored presented\"\n",
      "Topic: 3 \n",
      "Words: 0.067*\"google\" + 0.050*\"microsoft\" + 0.041*\"company\" + 0.040*\"today\" + 0.024*\"window\" + 0.024*\"customer\" + 0.023*\"service\" + 0.018*\"year\" + 0.014*\"update\" + 0.014*\"samsung\"\n",
      "Topic: 4 \n",
      "Words: 0.060*\"company\" + 0.042*\"week\" + 0.038*\"funding\" + 0.034*\"round\" + 0.031*\"startup\" + 0.026*\"today\" + 0.023*\"business\" + 0.022*\"investor\" + 0.021*\"participation\" + 0.017*\"money\"\n",
      "Topic: 5 \n",
      "Words: 0.089*\"guest\" + 0.050*\"ai\" + 0.037*\"artificial intelligence\" + 0.030*\"technology\" + 0.026*\"year\" + 0.020*\"machine\" + 0.018*\"machine learning\" + 0.017*\"industry\" + 0.016*\"future\" + 0.015*\"job\"\n",
      "Topic: 6 \n",
      "Words: 0.071*\"percent\" + 0.057*\"apple\" + 0.030*\"share\" + 0.027*\"company\" + 0.027*\"year\" + 0.026*\"revenue\" + 0.022*\"time\" + 0.017*\"month\" + 0.016*\"china\" + 0.014*\"u.s.\"\n",
      "Topic: 7 \n",
      "Words: 0.086*\"today\" + 0.081*\"company\" + 0.040*\"user\" + 0.028*\"developer\" + 0.018*\"bot\" + 0.018*\"twitter\" + 0.018*\"product\" + 0.017*\"people\" + 0.017*\"platform\" + 0.016*\"facebook\"\n",
      "Topic: 8 \n",
      "Words: 0.110*\"game\" + 0.059*\"pc\" + 0.047*\"playstation\" + 0.038*\"today\" + 0.032*\"player\" + 0.029*\"xbox one\" + 0.018*\"call\" + 0.018*\"november\" + 0.017*\"publisher\" + 0.017*\"studio\"\n",
      "Topic: 9 \n",
      "Words: 0.034*\"facebook\" + 0.034*\"vr\" + 0.032*\"video\" + 0.032*\"people\" + 0.031*\"virtual reality\" + 0.019*\"life\" + 0.018*\"friend\" + 0.017*\"youre\" + 0.015*\"blizzard\" + 0.014*\"effort\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(content_chunk_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.018*\"ceo\" + 0.015*\"tech\" + 0.014*\"news\" + 0.013*\"startup\" + 0.013*\"year\" + 0.012*\"sponsored\" + 0.012*\"president\" + 0.011*\"city\" + 0.011*\"san\" + 0.011*\"presented\"\n",
      "Topic: 1 \n",
      "Words: 0.047*\"google\" + 0.024*\"device\" + 0.021*\"home\" + 0.019*\"new\" + 0.018*\"smart\" + 0.018*\"assistant\" + 0.016*\"amazon\" + 0.015*\"guest\" + 0.013*\"company\" + 0.012*\"today\"\n",
      "Topic: 2 \n",
      "Words: 0.033*\"today\" + 0.031*\"new\" + 0.029*\"app\" + 0.029*\"user\" + 0.023*\"google\" + 0.023*\"service\" + 0.018*\"company\" + 0.018*\"feature\" + 0.016*\"developer\" + 0.015*\"available\"\n",
      "Topic: 3 \n",
      "Words: 0.037*\"today\" + 0.036*\"company\" + 0.032*\"venture\" + 0.029*\"startup\" + 0.027*\"release\" + 0.026*\"capital\" + 0.026*\"round\" + 0.025*\"press\" + 0.022*\"funding\" + 0.018*\"investor\"\n",
      "Topic: 4 \n",
      "Words: 0.035*\"ai\" + 0.031*\"guest\" + 0.028*\"microsoft\" + 0.027*\"intelligence\" + 0.024*\"artificial\" + 0.020*\"machine\" + 0.019*\"bot\" + 0.017*\"new\" + 0.015*\"technology\" + 0.013*\"window\"\n",
      "Topic: 5 \n",
      "Words: 0.050*\"reality\" + 0.044*\"vr\" + 0.040*\"virtual\" + 0.026*\"car\" + 0.019*\"new\" + 0.019*\"technology\" + 0.019*\"company\" + 0.016*\"headset\" + 0.012*\"oculus\" + 0.012*\"ar\"\n",
      "Topic: 6 \n",
      "Words: 0.032*\"company\" + 0.023*\"reuters\" + 0.022*\"u.s.\" + 0.019*\"year\" + 0.016*\"apple\" + 0.013*\"percent\" + 0.012*\"market\" + 0.009*\"share\" + 0.009*\"report\" + 0.009*\"last\"\n",
      "Topic: 7 \n",
      "Words: 0.100*\"game\" + 0.017*\"new\" + 0.016*\"pc\" + 0.016*\"studio\" + 0.013*\"today\" + 0.012*\"player\" + 0.012*\"playstation\" + 0.012*\"xbox\" + 0.011*\"developer\" + 0.010*\"war\"\n",
      "Topic: 8 \n",
      "Words: 0.024*\"week\" + 0.024*\"show\" + 0.021*\"amazon\" + 0.019*\"electronic\" + 0.017*\"entertainment\" + 0.016*\"alexa\" + 0.016*\"event\" + 0.016*\"los\" + 0.015*\"expo\" + 0.014*\"angeles\"\n",
      "Topic: 9 \n",
      "Words: 0.031*\"game\" + 0.028*\"live\" + 0.027*\"mobile\" + 0.019*\"event\" + 0.019*\"ad\" + 0.018*\"vb\" + 0.017*\"esports\" + 0.017*\"video\" + 0.016*\"marketing\" + 0.015*\"company\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(content_word_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF based LDA model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.299*\"google\" + 0.087*\"world\" + 0.040*\"chatbots\" + 0.037*\"destiny\" + 0.037*\"india\" + 0.035*\"rise\" + 0.030*\"others\" + 0.027*\"kid\" + 0.026*\"vr\" + 0.019*\"zelda breath\"\n",
      "Topic: 1 \n",
      "Words: 0.096*\"company\" + 0.071*\"uber\" + 0.065*\"pc\" + 0.055*\"future\" + 0.045*\"overwatch\" + 0.045*\"player\" + 0.038*\"machine learning\" + 0.034*\"hearthstone\" + 0.031*\"platform\" + 0.030*\"netflix\"\n",
      "Topic: 2 \n",
      "Words: 0.284*\"ai\" + 0.071*\"year\" + 0.066*\"samsung\" + 0.060*\"call\" + 0.041*\"people\" + 0.028*\"machine\" + 0.028*\"europe\" + 0.027*\"publisher\" + 0.022*\"september\" + 0.020*\"november\"\n",
      "Topic: 3 \n",
      "Words: 0.082*\"nintendo switch\" + 0.073*\"switch\" + 0.065*\"developer\" + 0.047*\"user\" + 0.044*\"esports\" + 0.042*\"job\" + 0.042*\"android\" + 0.036*\"data\" + 0.033*\"nintendo\" + 0.033*\"softbank\"\n",
      "Topic: 4 \n",
      "Words: 0.109*\"game\" + 0.063*\"u.s.\" + 0.049*\"fund\" + 0.045*\"time\" + 0.036*\"car\" + 0.036*\"tesla\" + 0.035*\"model\" + 0.035*\"revenue\" + 0.031*\"gamers\" + 0.025*\"alexa skills\"\n",
      "Topic: 5 \n",
      "Words: 0.074*\"october\" + 0.066*\"week\" + 0.051*\"trump\" + 0.044*\"tech\" + 0.044*\"life\" + 0.039*\"company\" + 0.034*\"team\" + 0.034*\"qualcomm\" + 0.032*\"human\" + 0.031*\"war\"\n",
      "Topic: 6 \n",
      "Words: 0.130*\"apple\" + 0.102*\"vr\" + 0.056*\"million\" + 0.051*\"investment\" + 0.048*\"virtual reality\" + 0.048*\"startup\" + 0.035*\"silicon valley\" + 0.027*\"marketer\" + 0.025*\"deanbeat\" + 0.023*\"investor\"\n",
      "Topic: 7 \n",
      "Words: 0.134*\"microsoft\" + 0.068*\"ai\" + 0.061*\"intel\" + 0.045*\"china\" + 0.039*\"playerunknown s battlegrounds\" + 0.034*\"alexa\" + 0.033*\"customer\" + 0.032*\"facebook\" + 0.030*\"vb live\" + 0.029*\"hero\"\n",
      "Topic: 8 \n",
      "Words: 0.118*\"amazon\" + 0.097*\"facebook\" + 0.060*\"bot\" + 0.055*\"twitter\" + 0.033*\"playstation\" + 0.033*\"google\" + 0.032*\"ar\" + 0.032*\"money\" + 0.025*\"video\" + 0.024*\"launch\"\n",
      "Topic: 9 \n",
      "Words: 0.061*\"business\" + 0.061*\"microsoft\" + 0.058*\"way\" + 0.043*\"iphone\" + 0.042*\"preview\" + 0.037*\"io\" + 0.035*\"new windows\" + 0.028*\"bitcoin\" + 0.028*\"ai\" + 0.027*\"december\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(title_chunk_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.024*\"ai\" + 0.022*\"game\" + 0.015*\"market\" + 0.011*\"new\" + 0.009*\"player\" + 0.008*\"ii\" + 0.008*\"fantasy\" + 0.008*\"office\" + 0.008*\"online\" + 0.008*\"mobile\"\n",
      "Topic: 1 \n",
      "Words: 0.020*\"google\" + 0.018*\"platform\" + 0.016*\"ai\" + 0.016*\"mobile\" + 0.015*\"twitter\" + 0.015*\"game\" + 0.012*\"weekly\" + 0.011*\"developer\" + 0.011*\"app\" + 0.010*\"new\"\n",
      "Topic: 2 \n",
      "Words: 0.025*\"vr\" + 0.016*\"google\" + 0.014*\"reality\" + 0.013*\"game\" + 0.012*\"ai\" + 0.012*\"startup\" + 0.012*\"virtual\" + 0.011*\"indie\" + 0.010*\"new\" + 0.009*\"facebook\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"new\" + 0.015*\"bot\" + 0.014*\"ai\" + 0.014*\"facebook\" + 0.012*\"amazon\" + 0.012*\"life\" + 0.012*\"microsoft\" + 0.010*\"launch\" + 0.010*\"google\" + 0.010*\"ar\"\n",
      "Topic: 4 \n",
      "Words: 0.017*\"playerunknown\" + 0.016*\"battleground\" + 0.014*\"apple\" + 0.014*\"business\" + 0.013*\"call\" + 0.012*\"duty\" + 0.011*\"data\" + 0.010*\"software\" + 0.010*\"year\" + 0.010*\"iphone\"\n",
      "Topic: 5 \n",
      "Words: 0.015*\"company\" + 0.014*\"switch\" + 0.013*\"chatbots\" + 0.013*\"live\" + 0.012*\"vb\" + 0.012*\"app\" + 0.011*\"car\" + 0.011*\"nintendo\" + 0.011*\"startup\" + 0.010*\"ceo\"\n",
      "Topic: 6 \n",
      "Words: 0.029*\"game\" + 0.024*\"—\" + 0.016*\"video\" + 0.016*\"review\" + 0.008*\"chip\" + 0.008*\"device\" + 0.008*\"switch\" + 0.007*\"hands-on\" + 0.007*\"startup\" + 0.007*\"human\"\n",
      "Topic: 7 \n",
      "Words: 0.020*\"ai\" + 0.018*\"game\" + 0.016*\"new\" + 0.015*\"microsoft\" + 0.012*\"people\" + 0.011*\"reality\" + 0.010*\"car\" + 0.010*\"robot\" + 0.010*\"creator\" + 0.010*\"alexa\"\n",
      "Topic: 8 \n",
      "Words: 0.019*\"google\" + 0.017*\"ai\" + 0.016*\"job\" + 0.012*\"amazon\" + 0.012*\"microsoft\" + 0.011*\"pixel\" + 0.010*\"learning\" + 0.009*\"machine\" + 0.009*\"marketing\" + 0.009*\"new\"\n",
      "Topic: 9 \n",
      "Words: 0.021*\"tech\" + 0.018*\"vr\" + 0.014*\"game\" + 0.014*\"uber\" + 0.013*\"technology\" + 0.011*\"first\" + 0.011*\"gaming\" + 0.009*\"blockchain\" + 0.009*\"platform\" + 0.009*\"company\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(title_word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.014*\"time\" + 0.013*\"year\" + 0.013*\"technology\" + 0.011*\"game\" + 0.008*\"ai\" + 0.008*\"today\" + 0.008*\"month\" + 0.008*\"company\" + 0.008*\"guest\" + 0.007*\"developer\"\n",
      "Topic: 1 \n",
      "Words: 0.014*\"today\" + 0.010*\"guest\" + 0.010*\"pc\" + 0.009*\"company\" + 0.009*\"world\" + 0.009*\"people\" + 0.008*\"press release\" + 0.008*\"game\" + 0.008*\"playstation\" + 0.008*\"microsoft\"\n",
      "Topic: 2 \n",
      "Words: 0.014*\"video\" + 0.010*\"today\" + 0.010*\"game\" + 0.010*\"october\" + 0.009*\"brand\" + 0.009*\"company\" + 0.009*\"world\" + 0.009*\"people\" + 0.009*\"player\" + 0.009*\"artificial intelligence\"\n",
      "Topic: 3 \n",
      "Words: 0.027*\"today\" + 0.017*\"company\" + 0.015*\"microsoft\" + 0.013*\"service\" + 0.009*\"team\" + 0.008*\"game\" + 0.008*\"people\" + 0.007*\"year\" + 0.007*\"window\" + 0.007*\"pc\"\n",
      "Topic: 4 \n",
      "Words: 0.020*\"game\" + 0.013*\"today\" + 0.012*\"sponsored presented\" + 0.011*\"company\" + 0.011*\"week\" + 0.010*\"year\" + 0.008*\"round\" + 0.008*\"report\" + 0.008*\"vr\" + 0.007*\"software\"\n",
      "Topic: 5 \n",
      "Words: 0.015*\"company\" + 0.012*\"today\" + 0.012*\"year\" + 0.010*\"user\" + 0.009*\"game\" + 0.008*\"customer\" + 0.008*\"launch\" + 0.008*\"month\" + 0.007*\"people\" + 0.006*\"facebook\"\n",
      "Topic: 6 \n",
      "Words: 0.015*\"today\" + 0.013*\"company\" + 0.011*\"guest\" + 0.010*\"funding\" + 0.010*\"year\" + 0.008*\"thing\" + 0.008*\"world\" + 0.008*\"july\" + 0.008*\"number\" + 0.007*\"june\"\n",
      "Topic: 7 \n",
      "Words: 0.011*\"people\" + 0.010*\"year\" + 0.010*\"google\" + 0.009*\"apple\" + 0.009*\"company\" + 0.008*\"game\" + 0.008*\"today\" + 0.008*\"investor\" + 0.008*\"intel\" + 0.007*\"match\"\n",
      "Topic: 8 \n",
      "Words: 0.013*\"company\" + 0.011*\"today\" + 0.011*\"game\" + 0.010*\"device\" + 0.010*\"google\" + 0.009*\"percent\" + 0.008*\"android\" + 0.008*\"player\" + 0.008*\"year\" + 0.008*\"io\"\n",
      "Topic: 9 \n",
      "Words: 0.019*\"company\" + 0.011*\"share\" + 0.009*\"startup\" + 0.009*\"today\" + 0.008*\"year\" + 0.007*\"business\" + 0.007*\"round\" + 0.007*\"reuters\" + 0.007*\"world\" + 0.007*\"vr\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(content_chunk_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"game\" + 0.006*\"company\" + 0.006*\"data\" + 0.006*\"new\" + 0.005*\"today\" + 0.005*\"vr\" + 0.004*\"ai\" + 0.004*\"google\" + 0.004*\"technology\" + 0.004*\"intelligence\"\n",
      "Topic: 1 \n",
      "Words: 0.006*\"company\" + 0.006*\"game\" + 0.005*\"venture\" + 0.005*\"round\" + 0.005*\"new\" + 0.004*\"funding\" + 0.004*\"today\" + 0.004*\"series\" + 0.004*\"ai\" + 0.004*\"technology\"\n",
      "Topic: 2 \n",
      "Words: 0.008*\"game\" + 0.005*\"company\" + 0.004*\"year\" + 0.004*\"new\" + 0.004*\"today\" + 0.004*\"way\" + 0.004*\"apple\" + 0.004*\"vr\" + 0.004*\"guest\" + 0.003*\"pc\"\n",
      "Topic: 3 \n",
      "Words: 0.008*\"game\" + 0.005*\"company\" + 0.005*\"vb\" + 0.005*\"new\" + 0.005*\"google\" + 0.005*\"event\" + 0.005*\"reality\" + 0.004*\"live\" + 0.004*\"year\" + 0.004*\"today\"\n",
      "Topic: 4 \n",
      "Words: 0.009*\"game\" + 0.007*\"google\" + 0.006*\"new\" + 0.005*\"today\" + 0.005*\"app\" + 0.004*\"developer\" + 0.004*\"alexa\" + 0.004*\"company\" + 0.004*\"ii\" + 0.004*\"studio\"\n",
      "Topic: 5 \n",
      "Words: 0.006*\"company\" + 0.006*\"release\" + 0.005*\"press\" + 0.005*\"today\" + 0.005*\"ai\" + 0.005*\"service\" + 0.005*\"platform\" + 0.005*\"new\" + 0.005*\"game\" + 0.005*\"technology\"\n",
      "Topic: 6 \n",
      "Words: 0.006*\"release\" + 0.006*\"press\" + 0.006*\"company\" + 0.006*\"game\" + 0.005*\"today\" + 0.005*\"technology\" + 0.005*\"firm\" + 0.005*\"data\" + 0.005*\"new\" + 0.004*\"startup\"\n",
      "Topic: 7 \n",
      "Words: 0.008*\"game\" + 0.006*\"new\" + 0.005*\"company\" + 0.005*\"today\" + 0.005*\"bot\" + 0.005*\"capital\" + 0.004*\"year\" + 0.004*\"venture\" + 0.004*\"round\" + 0.003*\"guest\"\n",
      "Topic: 8 \n",
      "Words: 0.008*\"game\" + 0.007*\"new\" + 0.007*\"window\" + 0.005*\"company\" + 0.005*\"today\" + 0.005*\"update\" + 0.005*\"microsoft\" + 0.004*\"apple\" + 0.004*\"android\" + 0.004*\"preview\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"game\" + 0.006*\"google\" + 0.006*\"new\" + 0.005*\"today\" + 0.005*\"switch\" + 0.005*\"company\" + 0.004*\"nintendo\" + 0.004*\"amazon\" + 0.004*\"device\" + 0.004*\"time\"\n"
     ]
    }
   ],
   "source": [
    "lda_model(content_word_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
